{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3eREw2pcdqm"
   },
   "source": [
    "# Basic RAG System with LangChain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is--iN7fcdqz"
   },
   "source": [
    "# QA Search Engine using Large Language Models - ChatGPT\n",
    "\n",
    "Here we use an Open AI LLM to generate contextual embeddings for each wikipedia article.\n",
    "\n",
    "Then we use ChatGPT (GPT3.5) to answer questions just as a human would by searching for the most similar articles based on our input queries.\n",
    "\n",
    "The new model, `text-embedding-3-small` is our new highly efficient embedding model and provides a significant upgrade over its predecessor, the `text-embedding-ada-002` model released in December 2022.\n",
    "\n",
    "GPT-3.5 models can understand and generate natural language or code. The most capable and cost effective model in the GPT-3.5 family is `gpt-3.5-turbo` which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiC3bewyVzQC"
   },
   "source": [
    "## QA Search Engine using Large Language Models - ChatGPT\n",
    "\n",
    "Here we use an Open AI LLM to generate contextual embeddings for each wikipedia article.\n",
    "\n",
    "Then we use ChatGPT (GPT3.5) to answer questions just as a human would by searching for the most similar article based on our input queries.\n",
    "\n",
    "The new model, `text-embedding-3-small` is our new highly efficient embedding model and provides a significant upgrade over its predecessor, the `text-embedding-ada-002` model released in December 2022.\n",
    "\n",
    "Stronger performance. Comparing `text-embedding-ada-002` to `text-embedding-3-small`, the average score on a commonly used benchmark for multi-language retrieval (MIRACL(opens in a new window)) has increased from 31.4% to 44.0%, while the average score on a commonly used benchmark for English tasks (MTEB(opens in a new window)) has increased from 61.0% to 62.3%.\n",
    "\n",
    "Reduced price. `text-embedding-3-small` is also substantially more efficient than our previous generation `text-embedding-ada-002` model. Pricing for `text-embedding-3-small` has therefore been reduced by 5X compared to `text-embedding-ada-002`, from a price per 1k tokens of $0.0001 to $0.00002.\n",
    "\n",
    "GPT-3.5 models can understand and generate natural language or code. The most capable and cost effective model in the GPT-3.5 family is `gpt-3.5-turbo` which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPj5mhnc4lp_"
   },
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3J_Z9mKEa8fM",
    "outputId": "994aba80-9238-40a6-937f-4be1fc63ee26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.16\n",
      "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (3.10.10)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.16)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain==0.1.16)\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain==0.1.16)\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.16)\n",
      "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.32.3)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.1.16)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.17.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.16) (3.0.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain==0.1.16)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.14.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.2.2)\n",
      "Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, packaging, mypy-extensions, typing-inspect, marshmallow, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.13\n",
      "    Uninstalling langchain-core-0.3.13:\n",
      "      Successfully uninstalled langchain-core-0.3.13\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.0\n",
      "    Uninstalling langchain-text-splitters-0.3.0:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.0\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.4\n",
      "    Uninstalling langchain-0.3.4:\n",
      "      Successfully uninstalled langchain-0.3.4\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-0.1.16 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 marshmallow-3.23.1 mypy-extensions-1.0.0 packaging-23.2 tenacity-8.5.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRL1gCk2kRvh",
    "outputId": "1cc565f1-8827-4d64-9f5b-bdb327ea06dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai==0.1.3\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.3) (0.1.53)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.3) (1.52.2)\n",
      "Collecting tiktoken<1,>=0.5.2 (from langchain-openai==0.1.3)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (0.1.137)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (2.9.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (8.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2.2.3)\n",
      "Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.1.3 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai==0.1.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vi15LA-RkRvh",
    "outputId": "ad2cbe54-b82c-4d17-f049-ff03a8b38494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community==0.0.33\n",
      "  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.43 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (0.1.53)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.33) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.33) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (2.9.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.33) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.33) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.33) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (1.2.2)\n",
      "Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain-community\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.38\n",
      "    Uninstalling langchain-community-0.0.38:\n",
      "      Successfully uninstalled langchain-community-0.0.38\n",
      "Successfully installed langchain-community-0.0.33\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community==0.0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9SJBRTmdiF5",
    "outputId": "396165f5-f0ba-4537-e843-167b7a614a79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-chroma==0.1.0\n",
      "  Downloading langchain_chroma-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting chromadb<0.5.0,>=0.4.0 (from langchain-chroma==0.1.0)\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting fastapi<1,>=0.95.2 (from langchain-chroma==0.1.0)\n",
      "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma==0.1.0) (0.1.53)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma==0.1.0) (1.26.4)\n",
      "Collecting build>=1.0.3 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.9.2)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (4.12.2)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.16.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.19.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (4.66.6)\n",
      "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.64.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.12.5)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.10.10)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi<1,>=0.95.2->langchain-chroma==0.1.0)\n",
      "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (0.1.137)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (23.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.27.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (0.27.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (1.0.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.2.14)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (75.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.65.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading opentelemetry_sdk-1.28.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading opentelemetry_util_http-0.49b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.16.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (8.5.0)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.10)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (3.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.24.7)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (13.9.3)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (1.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (4.9)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (1.0.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.20.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.18.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.6.1)\n",
      "Downloading langchain_chroma-0.1.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.28.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl (159 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.28.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_util_http-0.49b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.28.0-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=140d7aab728629ccfdf4172c0d9ed00ef9ed0920b03500733af003ddf187b0bb\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, uvicorn, python-dotenv, pyproject_hooks, pulsar-client, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.16.0\n",
      "    Uninstalling opentelemetry-api-1.16.0:\n",
      "      Successfully uninstalled opentelemetry-api-1.16.0\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.16.0\n",
      "    Uninstalling opentelemetry-sdk-1.16.0:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
      "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
      "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.3 which is incompatible.\n",
      "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
      "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.4 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 langchain-chroma-0.1.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.0 opentelemetry-api-1.28.0 opentelemetry-exporter-otlp-proto-common-1.28.0 opentelemetry-exporter-otlp-proto-grpc-1.28.0 opentelemetry-instrumentation-0.49b0 opentelemetry-instrumentation-asgi-0.49b0 opentelemetry-instrumentation-fastapi-0.49b0 opentelemetry-proto-1.28.0 opentelemetry-sdk-1.28.0 opentelemetry-semantic-conventions-0.49b0 opentelemetry-util-http-0.49b0 overrides-7.7.0 posthog-3.7.0 protobuf-5.28.3 pulsar-client-3.5.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.41.2 uvicorn-0.32.0 uvloop-0.21.0 watchfiles-0.24.0 websockets-13.1\n",
      "Collecting langchainhub==0.1.15\n",
      "  Downloading langchainhub-0.1.15-py3-none-any.whl.metadata (621 bytes)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchainhub==0.1.15) (2.32.3)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub==0.1.15)\n",
      "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub==0.1.15) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub==0.1.15) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub==0.1.15) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub==0.1.15) (2024.8.30)\n",
      "Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.15 types-requests-2.32.0.20241016\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-chroma==0.1.0\n",
    "!pip install langchainhub==0.1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dZr2lAGfkmSY"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtBa7rlWJWH3"
   },
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Av1UpSgXZUsI",
    "outputId": "6671fdbf-c24b-4335-b7c9-ad0cbca3b0d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "··········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5rOqCyianbP"
   },
   "source": [
    "if using Azure Open AI you might need to configure it based on how it is setup in your org.\n",
    "\n",
    "Refer to [this](https://python.langchain.com/docs/integrations/llms/azure_openai/) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1PIStD04Zp9p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmUCqWtf5gpk"
   },
   "source": [
    "### Load Wikipedia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQjM-gKUDT1Q",
    "outputId": "651b2bde-9a58-44bc-b9c7-363f56098913"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50.2M/50.2M [00:05<00:00, 9.15MB/s]\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Download a file from a URL\n",
    "def http_get(url, path) -> None:\n",
    "    \"\"\"\n",
    "    Downloads a URL to a given path on disc\n",
    "    \"\"\"\n",
    "    if os.path.dirname(path) != \"\":\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    req = requests.get(url, stream=True)\n",
    "    if req.status_code != 200:\n",
    "        print(\"Exception when trying to download {}. Response {}\".format(url, req.status_code), file=sys.stderr)\n",
    "        req.raise_for_status()\n",
    "        return\n",
    "\n",
    "    download_filepath = path + \"_part\"\n",
    "    with open(download_filepath, \"wb\") as file_binary:\n",
    "        content_length = req.headers.get(\"Content-Length\")\n",
    "        total = int(content_length) if content_length is not None else None\n",
    "        progress = tqdm(unit=\"B\", total=total, unit_scale=True)\n",
    "        for chunk in req.iter_content(chunk_size=1024):\n",
    "            if chunk:  # filter out keep-alive new chunks\n",
    "                progress.update(len(chunk))\n",
    "                file_binary.write(chunk)\n",
    "\n",
    "    os.rename(download_filepath, path)\n",
    "    progress.close()\n",
    "\n",
    "\n",
    "wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
    "\n",
    "http_get('http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz', wikipedia_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_NrBVzteHaZ",
    "outputId": "b0d93f7a-0adf-4bfd-a780-923c0eecf62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passages: 169597\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
    "\n",
    "passages = []\n",
    "with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        data = json.loads(line.strip())\n",
    "\n",
    "        #Add all paragraphs\n",
    "        #passages.extend(data['paragraphs'])\n",
    "\n",
    "        #Only add the first paragraph\n",
    "        passages.append(data['paragraphs'][0])\n",
    "\n",
    "print(\"Passages:\", len(passages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Id4P7kZ-DT1R"
   },
   "outputs": [],
   "source": [
    "# We subset our data so we only use a subset of wikipedia to run things faster\n",
    "passages = [passage for passage in passages for x in ['fish', 'india', 'cheetah']\n",
    "              if x in passage.lower().split()]\n",
    "passages = [passage for passage in passages for x in ['flying fish', 'india', 'cheetah']\n",
    "              if x in passage.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e13_oFtlDT1S",
    "outputId": "dcf58ece-3b0a-450c-848b-d27eaa67800e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "sm77itlPEDx0",
    "outputId": "906f99d2-88c6-46c5-e153-f4b09c24671e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Basil (\"Ocimum basilicum\") ( or ) is a plant of the Family Lamiaceae. It is also known as Sweet Basil or Tulsi. It is a tender low-growing herb that is grown as a perennial in warm, tropical climates. Basil is originally native to India and other tropical regions of Asia. It has been cultivated there for more than 5,000 years. It is prominently featured in many cuisines throughout the world. Some of them are Italian, Thai, Vietnamese and Laotian cuisines. It grows to between 30–60\\xa0cm tall. It has light green, silky leaves 3–5\\xa0cm long and 1–3\\xa0cm broad. The leaves are opposite each other. The flowers are quite big. They are white in color and arranged as a spike.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZUxQwCl5jY-"
   },
   "source": [
    "### Load Open AI LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "0NKUgjxLL-Ux"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1nD_kYA5ncq"
   },
   "source": [
    "### Generate LLM Embeddings and store them in Chroma Vector DB\n",
    "\n",
    "**Chroma Vector DB** is a versatile, open-source vector database designed for managing and querying vector embeddings. It is easy to set up and integrates well with various AI tools and algorithms. Chroma is particularly useful for applications that require rapid and precise retrieval of content represented as embeddings—efficient data formats for text, images, and soon, audio and video.\n",
    "\n",
    "**Key Features:**\n",
    "- **Integration with AI Tools:** Chroma supports embedding functions from leading providers like OpenAI, Google, and Hugging Face, allowing for flexible and powerful data handling.\n",
    "- **Ease of Use:** The database provides default embedding functions, or users can integrate external APIs to generate embeddings.\n",
    "- **Efficient Querying:** Users can create collections to store embeddings, documents, and metadata. These can be queried to retrieve the most similar items, making information retrieval quick and effective.\n",
    "- **Flexible API:** Chroma offers a straightforward API that supports both standard operations and custom embedding functions.\n",
    "\n",
    "For more detailed information, visit the official Chroma documentation [here](https://docs.trychroma.com).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbEe-0csNRmB",
    "outputId": "96420b9a-47ae-4b72-8d92-5e6cdf19a076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Basil (\"Ocimum basilicum\") ( or ) is a plant of the Family Lamiaceae. It is also known as Sweet Basil or Tulsi. It is a tender low-growing herb that is grown as a perennial in warm, tropical climates. Basil is originally native to India and other tropical regions of Asia. It has been cultivated there for more than 5,000 years. It is prominently featured in many cuisines throughout the world. Some of them are Italian, Thai, Vietnamese and Laotian cuisines. It grows to between 30–60\\xa0cm tall. It has light green, silky leaves 3–5\\xa0cm long and 1–3\\xa0cm broad. The leaves are opposite each other. The flowers are quite big. They are white in color and arranged as a spike.',\n",
       " 'The Roerich Pact is a treaty on Protection of Artistic and Scientific Institutions and Historic Monuments, signed by the representatives of 21 states in the Oval Office of the White House on 15 April 1935. As of January 1, 1990, the Roerich Pact had been ratified by ten nations: Brazil, Chile, Colombia, Cuba, the Dominican Republic, El Salvador, Guatemala, Mexico, the United States, and Venezuela. It went into effect on 26 August 1935. The Government of India approved the Treaty in 1948, but did not take any further formal action. The Roerich Pact is also known as \"Pax Cultura\" (\"Cultural Peace\" or \"Peace through Culture\"). The most important part of the Roerich Pact is the legal recognition that the protection of culture is always more important than any military necessity.',\n",
       " \"The Indian Air Force is the air arm of the Indian Military. The Royal Indian Air Force was founded on 1 April 1932 as part of the armed forces of the British Empire. In 1950, after independence, India dropped the word 'Royal' from the name.\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "HyFSs6xZfzok"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KPRVzeE6NwE7"
   },
   "outputs": [],
   "source": [
    "# The vectorstore we'll be using\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# The embedding engine that will convert our text to vectors\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Xt-9DpXxXscN"
   },
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "docs = [Document(page_content=doc) for doc in passages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3jwYefVL78q",
    "outputId": "0f2ee34a-43db-4a00-90c0-43b084e99665"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Basil (\"Ocimum basilicum\") ( or ) is a plant of the Family Lamiaceae. It is also known as Sweet Basil or Tulsi. It is a tender low-growing herb that is grown as a perennial in warm, tropical climates. Basil is originally native to India and other tropical regions of Asia. It has been cultivated there for more than 5,000 years. It is prominently featured in many cuisines throughout the world. Some of them are Italian, Thai, Vietnamese and Laotian cuisines. It grows to between 30–60\\xa0cm tall. It has light green, silky leaves 3–5\\xa0cm long and 1–3\\xa0cm broad. The leaves are opposite each other. The flowers are quite big. They are white in color and arranged as a spike.'),\n",
       " Document(page_content='The Roerich Pact is a treaty on Protection of Artistic and Scientific Institutions and Historic Monuments, signed by the representatives of 21 states in the Oval Office of the White House on 15 April 1935. As of January 1, 1990, the Roerich Pact had been ratified by ten nations: Brazil, Chile, Colombia, Cuba, the Dominican Republic, El Salvador, Guatemala, Mexico, the United States, and Venezuela. It went into effect on 26 August 1935. The Government of India approved the Treaty in 1948, but did not take any further formal action. The Roerich Pact is also known as \"Pax Cultura\" (\"Cultural Peace\" or \"Peace through Culture\"). The most important part of the Roerich Pact is the legal recognition that the protection of culture is always more important than any military necessity.'),\n",
       " Document(page_content=\"The Indian Air Force is the air arm of the Indian Military. The Royal Indian Air Force was founded on 1 April 1932 as part of the armed forces of the British Empire. In 1950, after independence, India dropped the word 'Royal' from the name.\")]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "P_9jsBAJWMk5"
   },
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300)\n",
    "chunked_docs = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Tu4rqnWYLFI",
    "outputId": "449732a2-bc11-4523-d10b-f963084b26c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Basil (\"Ocimum basilicum\") ( or ) is a plant of the Family Lamiaceae. It is also known as Sweet Basil or Tulsi. It is a tender low-growing herb that is grown as a perennial in warm, tropical climates. Basil is originally native to India and other tropical regions of Asia. It has been cultivated there for more than 5,000 years. It is prominently featured in many cuisines throughout the world. Some of them are Italian, Thai, Vietnamese and Laotian cuisines. It grows to between 30–60\\xa0cm tall. It has light green, silky leaves 3–5\\xa0cm long and 1–3\\xa0cm broad. The leaves are opposite each other. The flowers are quite big. They are white in color and arranged as a spike.'),\n",
       " Document(page_content='The Roerich Pact is a treaty on Protection of Artistic and Scientific Institutions and Historic Monuments, signed by the representatives of 21 states in the Oval Office of the White House on 15 April 1935. As of January 1, 1990, the Roerich Pact had been ratified by ten nations: Brazil, Chile, Colombia, Cuba, the Dominican Republic, El Salvador, Guatemala, Mexico, the United States, and Venezuela. It went into effect on 26 August 1935. The Government of India approved the Treaty in 1948, but did not take any further formal action. The Roerich Pact is also known as \"Pax Cultura\" (\"Cultural Peace\" or \"Peace through Culture\"). The most important part of the Roerich Pact is the legal recognition that the protection of culture is always more important than any military necessity.'),\n",
       " Document(page_content=\"The Indian Air Force is the air arm of the Indian Military. The Royal Indian Air Force was founded on 1 April 1932 as part of the armed forces of the British Empire. In 1950, after independence, India dropped the word 'Royal' from the name.\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RXepcnd1E7b"
   },
   "source": [
    "## Create Vector DB and Retriever\n",
    "\n",
    "If you have already created `wiki_db`in the previous hands-on session then just load the DB and DO NOT run the following code to create the database again, ignore this when running on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "er1Qz3D1k-Wc"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-35-turbo\",  # or your deployment\n",
    "    api_version=\"2023-06-01-preview\",  # or your api version\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    openai_api_key=\"****************************************************\",  # Replace with your actual API key\n",
    "    azure_endpoint=\"******************************************\",  # Changed from openai_api_base to azure_endpoint\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVVEa1h6obUc"
   },
   "outputs": [],
   "source": [
    "!pip install langchain openai tiktoken chromadb\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Assuming you have your OpenAI API key set in the environment variable OPENAI_API_KEY\n",
    "#openai_embed_model = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "# create vector DB of docs and embeddings\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunked_docs,\n",
    "    collection_name='wiki_db',\n",
    "    embedding=openai_embed_model,  # Now using the instantiated embedding model\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "    persist_directory=\"./wiki_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_st2XDc3N2Kf"
   },
   "outputs": [],
   "source": [
    "# create vector DB of docs and embeddings - takes 1 min on Colab\n",
    "chroma_db = Chroma.from_documents(documents=chunked_docs, collection_name='wiki_db',\n",
    "                                  embedding=OpenAIEmbeddings(),\n",
    "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
    "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
    "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                                  persist_directory=\"./wiki_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "-b3ReiW6qYBW",
    "outputId": "6eafea5f-954e-4afe-ac45-8b1e21ee1854"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n# Now, import and use AzureOpenAIEmbeddings\\nfrom langchain_openai import AzureOpenAIEmbeddings\\nfrom langchain.vectorstores import Chroma\\n\\n# **Change 1: Verify deployment name**\\n# Replace \\'text-embedding-ada-002\\' with the actual name of your embedding deployment \\n# in your Azure OpenAI resource. \\n# You can find this in the Azure portal.\\ndeployment_name = \"text-embedding-3-large\" # Update with correct name\\n\\n# create vector DB of docs and embeddings - takes 1 min on Colab\\nchroma_db = Chroma.from_documents(\\n    documents=chunked_docs, \\n    collection_name=\\'wiki_db\\',\\n    embedding=AzureOpenAIEmbeddings(\\n        deployment=deployment_name # **Change 2: Use the deployment_name variable**\\n    ),  \\n    collection_metadata={\"hnsw:space\": \"cosine\"},\\n    persist_directory=\"./wiki_db\"\\n)\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Ensure the AZURE_OPENAI_ENDPOINT is set correctly with your endpoint\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"********************************\"  # Replace with your actual endpoint\n",
    "\n",
    "# Ensure the AZURE_OPENAI_API_KEY is set\n",
    "if \"AZURE_OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\n",
    "        \"********************************************\"\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "# Now, import and use AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# **Change 1: Verify deployment name**\n",
    "# Replace 'text-embedding-ada-002' with the actual name of your embedding deployment\n",
    "# in your Azure OpenAI resource.\n",
    "# You can find this in the Azure portal.\n",
    "deployment_name = \"text-embedding-3-large\" # Update with correct name\n",
    "\n",
    "# create vector DB of docs and embeddings - takes 1 min on Colab\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunked_docs,\n",
    "    collection_name='wiki_db',\n",
    "    embedding=AzureOpenAIEmbeddings(\n",
    "        deployment=deployment_name # **Change 2: Use the deployment_name variable**\n",
    "    ),\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "    persist_directory=\"./wiki_db\"\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "vkJ2UiFmwXRO"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# ... (Rest of the code)\n",
    "\n",
    "# **Change:** Update deployment name to the correct one\n",
    "deployment_name = \"text-embedding-ada-002\"\n",
    "\n",
    "# create vector DB of docs and embeddings - takes 1 min on Colab\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunked_docs,\n",
    "    collection_name='wiki_db',\n",
    "    embedding=AzureOpenAIEmbeddings(\n",
    "        deployment=deployment_name\n",
    "    ),\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "    persist_directory=\"./wiki_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "hkERCGy2ps6v",
    "outputId": "21abe664-7d93-4635-a044-cd079e471356"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n# create vector DB of docs and embeddings - takes 1 min on Colab\\nfrom langchain_openai import AzureOpenAIEmbeddings\\nchroma_db = Chroma.from_documents(documents=chunked_docs, collection_name=\\'wiki_db\\',\\n                                  embedding=AzureOpenAIEmbeddings(),\\n                                  # need to set the distance function to cosine else it uses euclidean by default\\n                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\\n                                  collection_metadata={\"hnsw:space\": \"cosine\"},\\n                                  persist_directory=\"./wiki_db\")\\n                                  '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# create vector DB of docs and embeddings - takes 1 min on Colab\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "chroma_db = Chroma.from_documents(documents=chunked_docs, collection_name='wiki_db',\n",
    "                                  embedding=AzureOpenAIEmbeddings(),\n",
    "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
    "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
    "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                                  persist_directory=\"./wiki_db\")\n",
    "                                  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ju_zBIj1Zsb"
   },
   "source": [
    "## Load Vector DB from disk\n",
    "\n",
    "Run the following code if your vector DB already exists on disk from the previous hands-on session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "pNvj0dDH1WDg"
   },
   "outputs": [],
   "source": [
    "# load from disk\n",
    "chroma_db = Chroma(persist_directory=\"./wiki_db\",\n",
    "                   collection_name='wiki_db',\n",
    "                   embedding_function=AzureOpenAIEmbeddings(\n",
    "        deployment=deployment_name\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFC3uPqYop0a",
    "outputId": "1e8908a7-ba14-403a-cf56-941feb606710"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x7af11a274730>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "pTmvHpCRlXOO"
   },
   "outputs": [],
   "source": [
    "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                                              search_kwargs={\"k\": 5, \"score_threshold\": 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXzDAhu9YHY7",
    "outputId": "25fbaf5e-c34a-436c-ec37-bedf7d6c493c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'),\n",
       " Document(page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'),\n",
       " Document(page_content='Gandhinagar is the capital city of Gujarat state in India. It is 23\\xa0km from the city of Ahmedabad and 464\\xa0km from Mumbai. In the year 1960, the Bombay state of India was divided into two states - Maharashtra and Gujarat. Bombay (now called Mumbai) became the capital city of Maharashtra. For Gujarat, new capital was needed. Gandhinagar was then made the capital of Gujarat.'),\n",
       " Document(page_content='Gandhinagar is the capital city of Gujarat state in India. It is 23\\xa0km from the city of Ahmedabad and 464\\xa0km from Mumbai. In the year 1960, the Bombay state of India was divided into two states - Maharashtra and Gujarat. Bombay (now called Mumbai) became the capital city of Maharashtra. For Gujarat, new capital was needed. Gandhinagar was then made the capital of Gujarat.'),\n",
       " Document(page_content=\"Kolkata (spelled Calcutta before 1 January 2001) is the capital city of the Indian state of West Bengal. It is the second largest city in India after Mumbai. It is on the east bank of the River Hooghly. When it is called Calcutta, it includes the suburbs. This makes it the third largest city of India. This also makes it the world's 8th largest metropolitan area as defined by the United Nations. Kolkata served as the capital of India during the British Raj until 1911. Kolkata was once the center of industry and education. However, it has witnessed political violence and economic problems since 1954. Since 2000, Kolkata has grown due to economic growth. Like other metropolitan cities in India, Kolkata struggles with poverty, pollution and traffic congestion.\")]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_retriever.invoke('what is the capital of India?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bfn4Z4Em55bb"
   },
   "source": [
    "### Build a QA RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "vHAf9pJhjiMa"
   },
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNKFORDLji7f",
    "outputId": "d276da9a-8694-4d4e-e453-e8c24de3d887"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "8Pu5U9HNkl-q"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "            Use the following pieces of retrieved context to answer the question.\n",
    "            If you don't know the answer, just say that you don't know.\n",
    "            Keep the answer upto 5 lines unless the user asks for more information\n",
    "\n",
    "            Question:\n",
    "            {question}\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Answer:\n",
    "         \"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng4cKPYfmRyg"
   },
   "source": [
    "## New LangChain Syntax for RAG Chain - Using LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "18p2bJahmLX_"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_rag_chain = (\n",
    "    {\n",
    "        \"context\": (similarity_retriever\n",
    "                      |\n",
    "                    format_docs),\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "      |\n",
    "    prompt_template\n",
    "      |\n",
    "    chatgpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njFlSt9Smznk",
    "outputId": "5f8ee2da-b32e-4814-f938-c5b7e0d818d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the capital of India?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OfsGdmhnn6u",
    "outputId": "338dc9a2-571d-45e3-e869-23e7228b201d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The financial capital of India is Mumbai, which is home to the National Stock Exchange of India (NSE), the largest stock exchange in the country. Mumbai is a major financial hub, hosting numerous financial institutions, banks, and corporate headquarters. The NSE plays a crucial role in the Indian economy, being the third largest stock exchange in the world by transaction volume.\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about the financial capital of India\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PS5f9QKVn935",
    "outputId": "e796daed-f451-4d44-acad-717e08fb4f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who was the winner of the champions league in 2020?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0KunWF9Fnaj",
    "outputId": "38d52e22-401f-4333-eb28-66b4e4ade310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The financial capital of India is Mumbai. It is home to the National Stock Exchange of India (NSE), the largest stock exchange in the country, and the Reserve Bank of India (RBI), which is the central banking institution.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the financial capital of India?\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VwnV1fvWPILC",
    "outputId": "1ac83b0e-a3c7-44c1-a0cc-917af0c9e580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me more about it in detail\"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVemECCPfYg0"
   },
   "source": [
    "# Conversational RAG System with LangChain\n",
    "\n",
    "In many Q&A applications, the ability to engage in back-and-forth conversations with users is crucial. This necessitates the application having a form of \"memory\" to recall past interactions and apply this context to current queries.\n",
    "\n",
    "This guide focuses on integrating historical messages into the application's logic. Additional details on managing chat history can be found [here](https://python.langchain.com/docs/expression_language/how_to/message_history/).\n",
    "\n",
    "![](https://i.imgur.com/8hLJMPl.gif)\n",
    "\n",
    "### Building on the Q&A RAG System - to a Conversational Q&A RAG System\n",
    "\n",
    "We will enhance our Q&A RAG System, which utilizes the Wikipedia dataset, by implementing the following updates:\n",
    "\n",
    "- **Prompt Adjustment:** Our prompt will be modified to include historical messages as inputs, allowing the system to maintain context over the course of a conversation.\n",
    "\n",
    "- **Contextualizing Questions:** We will introduce a sub-chain mechanism to reformulate the latest user query by considering the chat history. This is crucial for understanding questions that refer back to previous messages. For example, a query like \"Can you elaborate on the second point?\" relies on the context provided by preceding interactions, which affects the system's ability to retrieve relevant information effectively.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0sMxGqEojYM"
   },
   "source": [
    "## Contextualizing the Question\n",
    "\n",
    "To maintain a seamless flow in conversations, especially in a Q&A setting, it's essential to incorporate historical interactions. Here’s how we achieve this:\n",
    "\n",
    "### Defining a Sub-Chain for Historical Context\n",
    "\n",
    "1. **Sub-Chain Creation:** We'll define a sub-chain that uses both historical messages and the latest user query. This sub-chain reformulates the question if it refers to any past interactions, ensuring the system, especially the vector database understands the context to return the most relevant documents to this newly reworded question.\n",
    "\n",
    "2. **Using `MessagesPlaceholder`:** Our prompt construction involves a `MessagesPlaceholder` variable named `chat_history`. This setup allows us to input a list of messages using the `chat_history` key. The system integrates these messages, positioning them after its own responses and before the latest user question.\n",
    "\n",
    "3. **Helper Function Usage:** We employ the `create_history_aware_retriever` function available [here](https://api.python.langchain.com/en/latest/chains/langchain.chains.history_aware_retriever.create_history_aware_retriever.html). This function is crucial for handling instances where the chat history might be empty and orchestrates the sequence of operations: `prompt | llm | StrOutputParser() | retriever`.\n",
    "\n",
    "4. **Chain Construction:** The `create_history_aware_retriever` constructs a chain that processes inputs under the keys `input` and `chat_history`, ensuring the output schema aligns with that of a retriever.\n",
    "\n",
    "By implementing these steps, our system can effectively utilize historical context to better understand and respond to user queries, thereby enhancing the conversational experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBXdc-uz4WSm",
    "outputId": "f6549127-c38a-4711-df2c-8621e255d2df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'input'], metadata={'lc_hub_owner': 'langchain-ai', 'lc_hub_repo': 'chat-langchain-rephrase', 'lc_hub_commit_hash': 'fb7ddb56be11b2ab10d176174dae36faa2a9a6ba13187c8b2b98315f6ca7d136'}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {input}\\nStandalone Question:')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rephrase_prompt = hub.pull(\"langchain-ai/chat-langchain-rephrase\")\n",
    "rephrase_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CG_6njQiGvjd",
    "outputId": "bb3c615a-38d7-4084-ec16-bc93e8836490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
      "\n",
      "Chat History:\n",
      "{chat_history}\n",
      "Follow Up Input: {input}\n",
      "Standalone Question:\n"
     ]
    }
   ],
   "source": [
    "print(rephrase_prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Drh0P1d2s0m",
    "outputId": "3c36b4ab-bfb9-4cd5-d4eb-435e66bf8df5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'AzureOpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7af11a274730>, search_type='similarity_score_threshold', search_kwargs={'k': 5, 'score_threshold': 0.2}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given a chat history and the latest user question\\nwhich might reference context in the chat history, formulate a standalone question\\nwhich can be understood without the chat history. Do NOT answer the question,\\njust reformulate it if needed and otherwise return it as is.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7af11a0ba320>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7af11a0bace0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'AzureOpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7af11a274730>, search_type='similarity_score_threshold', search_kwargs={'k': 5, 'score_threshold': 0.2})), config={'run_name': 'chat_retriever_chain'})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "rephrase_system_prompt = \"\"\"Given a chat history and the latest user question\n",
    "which might reference context in the chat history, formulate a standalone question\n",
    "which can be understood without the chat history. Do NOT answer the question,\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "rephrase_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", rephrase_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    chatgpt, similarity_retriever, rephrase_prompt\n",
    ")\n",
    "\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN2SIBOs29Si"
   },
   "source": [
    "This chain prepends a rephrasing of the input query to our retriever, so that the retrieval incorporates the context of the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67lm91Yl5eJg"
   },
   "source": [
    "## Building the QA RAG Chain with Chat History\n",
    "\n",
    "Now we're ready to construct our comprehensive QA RAG chain, which leverages historical context for more accurate and relevant responses.\n",
    "\n",
    "### Components of the QA RAG Chain\n",
    "\n",
    "1. **Creating Document Chains:**\n",
    "   - We use the `create_stuff_documents_chain` function, which is detailed [here](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html). This function is used to create a `question_answer_chain`, accepting inputs such as `context`, `chat_history`, and `input`. It efficiently combines the retrieved context with the conversation history and the current query to generate an informed answer.\n",
    "\n",
    "2. **Building the Final QA RAG Chain:**\n",
    "   - The entire QA RAG chain is assembled using the `create_retrieval_chain` function, available [here](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html). This chain integrates the `history_aware_retriever` with the `question_answer_chain`. It retains intermediate outputs like the retrieved context for added convenience during the query handling process.\n",
    "   - The `create_retrieval_chain` function accepts keys such as `input` and `chat_history` and includes `input`, `chat_history`, `context`, and `answer` in its outputs.\n",
    "\n",
    "By implementing these steps, the system not only contextualizes but also provides accurate answers by synthesizing information from both the current and historical interactions. This method enhances the conversational AI’s ability to understand and respond to user queries dynamically, making the interactions more engaging and relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8v6WgeG5KQa",
    "outputId": "938af5de-d2c5-4c23-a73a-0d516cf2af34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'AzureOpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7af11a274730>, search_type='similarity_score_threshold', search_kwargs={'k': 5, 'score_threshold': 0.2}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given a chat history and the latest user question\\nwhich might reference context in the chat history, formulate a standalone question\\nwhich can be understood without the chat history. Do NOT answer the question,\\njust reformulate it if needed and otherwise return it as is.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "           | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7af11a0ba320>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7af11a0bace0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "           | StrOutputParser()\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'AzureOpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7af11a274730>, search_type='similarity_score_threshold', search_kwargs={'k': 5, 'score_threshold': 0.2})), config={'run_name': 'retrieve_documents'})\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), config={'run_name': 'format_inputs'})\n",
       "            | ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"You are an assistant for question-answering tasks.\\n                      Use the following pieces of retrieved context to answer the question.\\n                      If you don't know the answer, just say that you don't know.\\n                      Keep the answer upto 5 lines unless the user asks for more information\\n\\n                      Context:\\n                      {context}\\n                  \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7af11a0ba320>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7af11a0bace0>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "            | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n",
       "  }), config={'run_name': 'retrieval_chain'})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "                      Use the following pieces of retrieved context to answer the question.\n",
    "                      If you don't know the answer, just say that you don't know.\n",
    "                      Keep the answer upto 5 lines unless the user asks for more information\n",
    "\n",
    "                      Context:\n",
    "                      {context}\n",
    "                  \"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(chatgpt, qa_prompt)\n",
    "\n",
    "qa_rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "qa_rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPguXvkG7b6c",
    "outputId": "52bec025-8dd6-453c-b393-32f596dd43b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "question = \"What is the capital of India?\"\n",
    "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Osi23E2zEDa",
    "outputId": "13a488b2-df68-433f-d706-afec0ee262b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What is the capital of India?', 'chat_history': []}\n",
      "{'context': [Document(page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'), Document(page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'), Document(page_content='Gandhinagar is the capital city of Gujarat state in India. It is 23\\xa0km from the city of Ahmedabad and 464\\xa0km from Mumbai. In the year 1960, the Bombay state of India was divided into two states - Maharashtra and Gujarat. Bombay (now called Mumbai) became the capital city of Maharashtra. For Gujarat, new capital was needed. Gandhinagar was then made the capital of Gujarat.'), Document(page_content='Gandhinagar is the capital city of Gujarat state in India. It is 23\\xa0km from the city of Ahmedabad and 464\\xa0km from Mumbai. In the year 1960, the Bombay state of India was divided into two states - Maharashtra and Gujarat. Bombay (now called Mumbai) became the capital city of Maharashtra. For Gujarat, new capital was needed. Gandhinagar was then made the capital of Gujarat.'), Document(page_content='The Republic of India is divided into twenty-eight States,and eight union territories including the National Capital Territory.')]}\n",
      "{'answer': ''}\n",
      "{'answer': 'The'}\n",
      "{'answer': ' capital'}\n",
      "{'answer': ' of'}\n",
      "{'answer': ' India'}\n",
      "{'answer': ' is'}\n",
      "{'answer': ' New'}\n",
      "{'answer': ' Delhi'}\n",
      "{'answer': '.'}\n",
      "{'answer': ''}\n"
     ]
    }
   ],
   "source": [
    "for chunk in qa_rag_chain.stream({\"input\": question, \"chat_history\": chat_history}):\n",
    "  print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZxkLV4bJkOt",
    "outputId": "a55cf13a-0dfe-4dab-f3ec-fe916072d70b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_fPkZ9P7rF4",
    "outputId": "b0058cc4-8d8e-477f-e19d-ba0db9b7f118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the capital of India?'),\n",
       " AIMessage(content='The capital of India is New Delhi.')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history.extend([HumanMessage(content=question),\n",
    "                     AIMessage(content=response[\"answer\"])])\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZRM06Y375LF",
    "outputId": "87469f9d-7bdb-48c3-c53e-800f683ffb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi is the capital of India and a union territory within the megacity of Delhi. It has a rich history and is home to several monuments. The city is known for being expensive to live in and falls under the North Indian geographical zone. It covers an area of about 42.7 km and has a population of approximately 9.4 million people.\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me more about this city\"\n",
    "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozckE4Hr8yOj",
    "outputId": "aaa7b96f-16a6-4ced-b95e-45ce6f6b0ba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the capital of India?'),\n",
       " AIMessage(content='The capital of India is New Delhi.'),\n",
       " HumanMessage(content='Tell me more about this city'),\n",
       " AIMessage(content='New Delhi is the capital of India and a union territory within the megacity of Delhi. It has a rich history and is home to several monuments. The city is known for being expensive to live in and falls under the North Indian geographical zone. It covers an area of about 42.7 km and has a population of approximately 9.4 million people.')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.extend([HumanMessage(content=question),\n",
    "                     AIMessage(content=response[\"answer\"])])\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQqNj73E8zVL",
    "outputId": "b2bf3634-85d4-42d1-e079-ec26927b0234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, some fish, like flying fish from the family Exocoetidae, can glide above the water's surface. They have winglike fins that allow them to glide for considerable distances to escape predators. However, they do not truly \"fly\" like birds; instead, they glide through the air after leaping out of the water.\n"
     ]
    }
   ],
   "source": [
    "question = \"Can fish really fly?\"\n",
    "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "op5Lb-9uJ5aI",
    "outputId": "5a1aa6dc-395d-4f76-cf28-42dbb7dc8f74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Can fish really fly?',\n",
       " 'chat_history': [HumanMessage(content='What is the capital of India?'),\n",
       "  AIMessage(content='The capital of India is New Delhi.'),\n",
       "  HumanMessage(content='Tell me more about this city'),\n",
       "  AIMessage(content='New Delhi is the capital of India and a union territory within the megacity of Delhi. It has a rich history and is home to several monuments. The city is known for being expensive to live in and falls under the North Indian geographical zone. It covers an area of about 42.7 km and has a population of approximately 9.4 million people.')],\n",
       " 'context': [Document(page_content='Flying fish are marine oceanic fishes of the family Exocoetidae. They are about 50 species, and they live worldwide in warm waters. They are noted for their ability to glide. They are all small, with a maximum length of about 45 cm (18 inches), and have winglike, rigid fins and an unevenly forked tail.'),\n",
       "  Document(page_content='Flying fish are marine oceanic fishes of the family Exocoetidae. They are about 50 species, and they live worldwide in warm waters. They are noted for their ability to glide. They are all small, with a maximum length of about 45 cm (18 inches), and have winglike, rigid fins and an unevenly forked tail.'),\n",
       "  Document(page_content='The flying snake, or \"Chrysopelea\", is a mildly venomous snake found throughout India to the Indonesian archipelago. It can glide, in an arboreal habitat, going from tree to tree, most likely, much like the draco lizard. They\\'re better at \"flying\" than another species of animal similar to this - the flying squirrel.'),\n",
       "  Document(page_content='The flying snake, or \"Chrysopelea\", is a mildly venomous snake found throughout India to the Indonesian archipelago. It can glide, in an arboreal habitat, going from tree to tree, most likely, much like the draco lizard. They\\'re better at \"flying\" than another species of animal similar to this - the flying squirrel.'),\n",
       "  Document(page_content='Bluefish is a kind of fish which occurs in the Atlantic Ocean, the Mediterranean, the Black Sea, the Indian Ocean and the Pacific. It is a pelagic fish, which means that it lives near the surface of the ocean. They can grow to a size of and reach a weight of . In the wild, they live to be about nine years old.')],\n",
       " 'answer': 'Yes, some fish, like flying fish from the family Exocoetidae, can glide above the water\\'s surface. They have winglike fins that allow them to glide for considerable distances to escape predators. However, they do not truly \"fly\" like birds; instead, they glide through the air after leaping out of the water.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "ra8o20RH88WQ"
   },
   "outputs": [],
   "source": [
    "chat_history.extend([HumanMessage(content=question),\n",
    "                     AIMessage(content=response[\"answer\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNkuQx7DezF5",
    "outputId": "72ad6896-fa44-44f1-b9c5-4929a5aa79e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the capital of India?'),\n",
       " AIMessage(content='The capital of India is New Delhi.'),\n",
       " HumanMessage(content='Tell me more about this city'),\n",
       " AIMessage(content='New Delhi is the capital of India and a union territory within the megacity of Delhi. It has a rich history and is home to several monuments. The city is known for being expensive to live in and falls under the North Indian geographical zone. It covers an area of about 42.7 km and has a population of approximately 9.4 million people.'),\n",
       " HumanMessage(content='Can fish really fly?'),\n",
       " AIMessage(content='Yes, some fish, like flying fish from the family Exocoetidae, can glide above the water\\'s surface. They have winglike fins that allow them to glide for considerable distances to escape predators. However, they do not truly \"fly\" like birds; instead, they glide through the air after leaping out of the water.')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84jh_iP5bEn5",
    "outputId": "3a549e8a-0821-4bf1-dfd4-5d206b1e1419"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Can fish really fly?'),\n",
       " AIMessage(content='Yes, some fish, like flying fish from the family Exocoetidae, can glide above the water\\'s surface. They have winglike fins that allow them to glide for considerable distances to escape predators. However, they do not truly \"fly\" like birds; instead, they glide through the air after leaping out of the water.')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5bN1VjaKT8n",
    "outputId": "fd05164d-809f-497f-8ce0-355bef93a7e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fastest land animal is the cheetah, which can run up to 112 kilometers per hour for short distances.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the fastest animal?\"\n",
    "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=question),\n",
    "                     AIMessage(content=response[\"answer\"])])\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7s3Ii71fKa9U",
    "outputId": "eb644c62-f4d8-40fe-de76-11376aa59d69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cheetahs have several subspecies, including:\n",
      "\n",
      "1. **Asiatic Cheetah (Acinonyx jubatus venaticus)**: A critically endangered subspecies native to Asia.\n",
      "2. **South African Cheetah (Acinonyx jubatus jubatus)**: The most abundant subspecies, found in Southern Africa, with an estimated population of over 6,000 individuals in the wild.\n",
      "\n",
      "These subspecies differ in their habitats and population status, with the Asiatic cheetah being particularly at risk.\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me about its different species\"\n",
    "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=question),\n",
    "                     AIMessage(content=response[\"answer\"])])\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xX-XlFK9UFz"
   },
   "source": [
    "## Returning Sources in Q&A Applications\n",
    "\n",
    "An essential feature of Q&A applications is the transparency in showing the sources that contributed to the generated answers. This builds trust and allows users to further explore the original content.\n",
    "\n",
    "### Integration with LangChain’s `create_retrieval_chain`\n",
    "\n",
    "- **Source Propagation:** LangChain’s `create_retrieval_chain` function is designed to ensure that source documents retrieved during the question answering process are included in the final output. This is particularly useful for maintaining transparency and providing users with the ability to trace answers back to their origins.\n",
    "- **Key Implementation:** The retrieved source documents are propagated through to the output under the \"context\" key. This feature not only supports the credibility of the answers provided but also enhances user engagement by allowing users to verify and explore the sources themselves.\n",
    "\n",
    "By utilizing this built-in functionality, developers can easily implement a system where users are always informed about the origins of the information provided, thereby enhancing the overall reliability and user experience of the Q&A application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "XXnvQpoXKzCE"
   },
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4NVMH2H9Aad",
    "outputId": "751bb884-d31f-44be-9908-f151cbe5e1ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The fastest land animal is the cheetah, which can run up to 112 kilometers per hour for a short time.\n",
      "Sources:\n",
      "page_content='A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.'\n",
      "\n",
      "page_content='A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.'\n",
      "\n",
      "page_content='The Asiatic cheetah (\"Acinonyx jubatus venaticus\") is a critically endangered subspecies of the cheetah native to Asia.'\n",
      "\n",
      "page_content='The Asiatic cheetah (\"Acinonyx jubatus venaticus\") is a critically endangered subspecies of the cheetah native to Asia.'\n",
      "\n",
      "page_content='The South African Cheetah (\"Acinonyx jubatus jubatus\"), also known as Namibian Cheetah, is the nominate subspecies of cheetah native to Southern Africa. It is the most abundant subspecies estimated at more than 6,000 individuals in the wild. Since 1990 and onwards, the population was estimated at approximately 2,500 individuals in Namibia, until 2015, the cheetah population has been increased to more than 3,500 in the country.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"which is the fastest animal?\"\n",
    "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "print('Answer:', response['answer'])\n",
    "print('Sources:')\n",
    "for document in response['context']:\n",
    "    print(document)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "hBUt6ZL89soR"
   },
   "outputs": [],
   "source": [
    "chat_history.extend([HumanMessage(content=question),\n",
    "                     AIMessage(content=response[\"answer\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzDIkfMk9z86",
    "outputId": "111575e0-1bbc-4b59-e645-bcaf4defaecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Cheetahs are medium large cats known for their incredible speed. There are several subspecies:\n",
      "\n",
      "1. **Asiatic Cheetah (Acinonyx jubatus venaticus)**: Critically endangered and native to Asia.\n",
      "2. **South African Cheetah (Acinonyx jubatus jubatus)**: The most abundant subspecies, found in Southern Africa, with an estimated population of over 6,000 individuals.\n",
      "\n",
      "Cheetahs primarily inhabit the savannas of Africa and are active during the day, hunting in the early morning or late evening.\n",
      "Sources:\n",
      "page_content='A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.'\n",
      "\n",
      "page_content='A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.'\n",
      "\n",
      "page_content='The Asiatic cheetah (\"Acinonyx jubatus venaticus\") is a critically endangered subspecies of the cheetah native to Asia.'\n",
      "\n",
      "page_content='The Asiatic cheetah (\"Acinonyx jubatus venaticus\") is a critically endangered subspecies of the cheetah native to Asia.'\n",
      "\n",
      "page_content='The South African Cheetah (\"Acinonyx jubatus jubatus\"), also known as Namibian Cheetah, is the nominate subspecies of cheetah native to Southern Africa. It is the most abundant subspecies estimated at more than 6,000 individuals in the wild. Since 1990 and onwards, the population was estimated at approximately 2,500 individuals in Namibia, until 2015, the cheetah population has been increased to more than 3,500 in the country.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me more, including different types of this animal and their details\"\n",
    "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "print('Answer:', response['answer'])\n",
    "print('Sources:')\n",
    "for document in response['context']:\n",
    "    print(document)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOFkt3K52SLt"
   },
   "source": [
    "# Multi-User Conversational RAG System with LangChain\n",
    "\n",
    "In many Q&A applications, the ability to engage in back-and-forth conversations with users is crucial. This necessitates the application having a form of \"memory\" to recall past interactions and apply this context to current queries.\n",
    "\n",
    "However in most real-world conversational systems, multiple users or user sessions will be accessing the system simultaneously.\n",
    "\n",
    "![](https://i.imgur.com/X4WivLu.gif)\n",
    "\n",
    "Here we will show how you can use `SQLChatMessageHistory` such that we can store separate conversation histories per user or session which is often the need for real-world chatbots which will be accessed by many users at the same time. Instead of in-memory we can store it in a SQL database which can be used to store a lot of conversations.\n",
    "\n",
    "We use a `get_session_history` function which is expected to take in a `session_id` and return a Message History object. Everything is stored in a SQL database. This `session_id` is used to distinguish between separate conversations, and should be passed in as part of the config when calling the new chain\n",
    "\n",
    "We also use a `memory_buffer_window` function to only use the top-K last historical conversations before sending it to the LLM, basically our own implementation of `ConversationBufferWindowMemory`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OnEXZ113TEp",
    "outputId": "ac5d5f3d-3a9f-4fbf-c162-bfc85ce4badb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'memory.db': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# removes the memory database file - usually not needed\n",
    "# you can run this only when you want to remove all conversation histories\n",
    "!rm memory.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "sleeltMX3WfG"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "######### REPHRASER ############\n",
    "rephrase_system_prompt = \"\"\"Given a chat history and the latest user question\n",
    "which might reference context in the chat history, formulate a standalone question\n",
    "which can be understood without the chat history. Do NOT answer the question,\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "rephrase_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", rephrase_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    chatgpt, similarity_retriever, rephrase_prompt\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "######### MULTI_USER RAG RESPONSE GENERATOR ############\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "                      Use the following pieces of retrieved context to answer the question.\n",
    "                      If you don't know the answer, just say that you don't know.\n",
    "                      Keep the answer upto 5 lines unless the user asks for more information\n",
    "\n",
    "                      Context:\n",
    "                      {context}\n",
    "                  \"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# used to retrieve conversation history from database\n",
    "# based on a specific user or session ID\n",
    "def get_session_history_db(session_id, topk_conversations=2):\n",
    "    history = SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
    "    #history.messages = history.messages[-2*topk_conversations:]\n",
    "    return history\n",
    "\n",
    "# subset historical conversations\n",
    "def memory_buffer_window(messages, topk_conversations=2): # each conversation has 2 messages - (human prompt, AI response)\n",
    "    return messages[-(topk_conversations*2):]\n",
    "\n",
    "# custom RAG chain which looks at last K conversational messages\n",
    "question_answer_chain = (\n",
    "    RunnablePassthrough.assign(chat_history=lambda x: memory_buffer_window(x[\"chat_history\"]))\n",
    "      |\n",
    "    qa_prompt\n",
    "      |\n",
    "    chatgpt\n",
    "      |\n",
    "    StrOutputParser()\n",
    ")\n",
    "qa_rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "############ CONVERSATIONAL RAG CHAIN ####################\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    qa_rag_chain,\n",
    "    get_session_history_db,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "B8Tx0vy3-bGp"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def conv_rag_chatbot(usersession_id, prompt):\n",
    "    response = conversational_rag_chain.invoke(\n",
    "                                {\"input\": prompt},\n",
    "                                config={\n",
    "                                    \"configurable\": {\"session_id\": usersession_id}\n",
    "                                }\n",
    "    )\n",
    "    print('Answer:')\n",
    "    display(Markdown(response['answer']))\n",
    "    print('Sources:')\n",
    "    for document in response['context']:\n",
    "        print(document)\n",
    "        print()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "QaPLZp3T-7hb",
    "outputId": "a84f061e-bbe2-4284-c2d8-fabda7580273"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.tracers.base:Parent run 1dfd4f01-01cd-4be0-9e6f-06a524058abb not found for run c52974e3-8f55-4fb3-a428-13bee0889ea9. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The capital of India is New Delhi."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sources:\n",
      "page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'\n",
      "\n",
      "page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'\n",
      "\n",
      "page_content='Gandhinagar is the capital city of Gujarat state in India. It is 23\\xa0km from the city of Ahmedabad and 464\\xa0km from Mumbai. In the year 1960, the Bombay state of India was divided into two states - Maharashtra and Gujarat. Bombay (now called Mumbai) became the capital city of Maharashtra. For Gujarat, new capital was needed. Gandhinagar was then made the capital of Gujarat.'\n",
      "\n",
      "page_content='Gandhinagar is the capital city of Gujarat state in India. It is 23\\xa0km from the city of Ahmedabad and 464\\xa0km from Mumbai. In the year 1960, the Bombay state of India was divided into two states - Maharashtra and Gujarat. Bombay (now called Mumbai) became the capital city of Maharashtra. For Gujarat, new capital was needed. Gandhinagar was then made the capital of Gujarat.'\n",
      "\n",
      "page_content='The Republic of India is divided into twenty-eight States,and eight union territories including the National Capital Territory.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_id = 'bond007'\n",
    "r = conv_rag_chatbot(us_id, 'What is the capital of India?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "XNwp9jKH74M2",
    "outputId": "d391dc2e-3e30-48a0-bcb1-a898a759c419"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.tracers.base:Parent run 031dd632-d736-48ea-8f06-9d882524cc4d not found for run ad5e1c77-6b1e-4e46-865c-53cd8a8a2b77. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "New Delhi is the capital of India and a union territory within the megacity of Delhi. It has a rich history and is known for its numerous monuments. The city covers an area of about 42.7 km² and has a population of approximately 9.4 million people. Geographically, it falls under the North Indian zone and is considered an expensive place to live."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sources:\n",
      "page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'\n",
      "\n",
      "page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'\n",
      "\n",
      "page_content='The Republic of India is divided into twenty-eight States,and eight union territories including the National Capital Territory.'\n",
      "\n",
      "page_content='The Republic of India is divided into twenty-eight States,and eight union territories including the National Capital Territory.'\n",
      "\n",
      "page_content='Central India is an Indian region.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = conv_rag_chatbot(us_id, 'Tell me more about it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "kZz9rmHs7b0h",
    "outputId": "da6fa62b-ce1b-4e74-c3e4-3e0861a1b1eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.tracers.base:Parent run 30e65721-0130-4545-bc9f-a8dc3dc01404 not found for run 181c23c7-19c8-4551-8d8f-0ce44f95ae9e. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The fastest land animal is the cheetah, which can run up to 112 kilometers per hour for a short time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sources:\n",
      "page_content='A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.'\n",
      "\n",
      "page_content='A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.'\n",
      "\n",
      "page_content='The Asiatic cheetah (\"Acinonyx jubatus venaticus\") is a critically endangered subspecies of the cheetah native to Asia.'\n",
      "\n",
      "page_content='The Asiatic cheetah (\"Acinonyx jubatus venaticus\") is a critically endangered subspecies of the cheetah native to Asia.'\n",
      "\n",
      "page_content='The Lamborghini Cheetah is an off-road prototype that was made by Lamborghini in 1977.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_id = 'jim003'\n",
    "r = conv_rag_chatbot(us_id, 'What is the fastest animal on land?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "OroRf99D7rZF",
    "outputId": "c2c0cb2a-961b-4154-abde-8ca3dc275028"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.tracers.base:Parent run 385607f3-788d-4178-826b-f916d8c7feae not found for run 5915008a-b2a3-4396-a56b-ee8f5242deb0. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "There are several subspecies of cheetah:\n",
       "\n",
       "1. **Asiatic Cheetah** (*Acinonyx jubatus venaticus*): A critically endangered subspecies native to Asia.\n",
       "2. **South African Cheetah** (*Acinonyx jubatus jubatus*): The most abundant subspecies, found in Southern Africa, with an estimated population of over 6,000 individuals in the wild.\n",
       "\n",
       "Most cheetahs live in the savannas of Africa, and there are a few in Asia."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sources:\n",
      "page_content='A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.'\n",
      "\n",
      "page_content='A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.'\n",
      "\n",
      "page_content='The Asiatic cheetah (\"Acinonyx jubatus venaticus\") is a critically endangered subspecies of the cheetah native to Asia.'\n",
      "\n",
      "page_content='The Asiatic cheetah (\"Acinonyx jubatus venaticus\") is a critically endangered subspecies of the cheetah native to Asia.'\n",
      "\n",
      "page_content='The South African Cheetah (\"Acinonyx jubatus jubatus\"), also known as Namibian Cheetah, is the nominate subspecies of cheetah native to Southern Africa. It is the most abundant subspecies estimated at more than 6,000 individuals in the wild. Since 1990 and onwards, the population was estimated at approximately 2,500 individuals in Namibia, until 2015, the cheetah population has been increased to more than 3,500 in the country.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = conv_rag_chatbot(us_id, 'tell me more about its different species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "icEp-_b984-r",
    "outputId": "5dd2c15f-f2ef-424c-e3ca-79e0965bea29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.tracers.base:Parent run 396639bf-803f-4c18-aac1-09fd91407184 not found for run 385f0408-81d9-45a0-8a14-8a5a364fb503. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The financial capital of India is Mumbai. It is home to the National Stock Exchange of India (NSE), which is the largest stock exchange in India and the third largest in the world by transaction volume. Mumbai is a major financial hub, housing numerous financial institutions, banks, and corporate headquarters."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sources:\n",
      "page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'\n",
      "\n",
      "page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'\n",
      "\n",
      "page_content='The National Stock Exchange of India Limited (NSE), is a Mumbai-based stock exchange. It is the biggest stock exchange in India and the third biggest in the world in terms of amounts of transactions. NSE is mutually-owned by a set of leading financial institutions, banks, insurance companies and other financial intermediaries in India but its ownership and management operate as separate groups. As of 2006, the NSE VSAT terminals, 2799 in total, cover more than 1500 cities across India. In July 2007, the NSE had a total market capitalization of 42,74,509 crore INR making it the second-largest stock market in South Asia in terms of market-capitalization.'\n",
      "\n",
      "page_content='The National Stock Exchange of India Limited (NSE), is a Mumbai-based stock exchange. It is the biggest stock exchange in India and the third biggest in the world in terms of amounts of transactions. NSE is mutually-owned by a set of leading financial institutions, banks, insurance companies and other financial intermediaries in India but its ownership and management operate as separate groups. As of 2006, the NSE VSAT terminals, 2799 in total, cover more than 1500 cities across India. In July 2007, the NSE had a total market capitalization of 42,74,509 crore INR making it the second-largest stock market in South Asia in terms of market-capitalization.'\n",
      "\n",
      "page_content=\"The Economy of India is the fifth largest in the world with a GDP (a year's goods and services) of $2.94 trillion (U.S.). If you consider PPP (purchasing power parity: how much that money can buy in India compared to other countries), the economy is third largest (worth $10.51 trillion U.S.). However, due to India's huge population, the economy was still only $6,209 (considering PPP) per person per year in 2015.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_id = 'bond007'\n",
    "r = conv_rag_chatbot(us_id, 'What about the financial capital of India?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdJxxitZBwAj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
